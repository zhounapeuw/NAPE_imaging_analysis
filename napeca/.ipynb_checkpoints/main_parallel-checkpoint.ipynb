{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAPE Calcium Imaging Preprocessing Pipeline\n",
    "\n",
    "Finds any .tif, .tiff, .h5 files in the requested directory and performs SIMA-based motion correction and fft-based bidirection \n",
    "offset correction, signal extraction, and neuropil correction. This code parallelizes the computation at the session level by passing the multiple file paths (if there are more than one recordings) to the multiprocessing map function. \n",
    "\n",
    "__IMPORTANT RECOMENDATION__: This pipeline requires the user to manually draw regions-of-interest (ROIs) on the mean image (usually the motion-corrected output) in imagej/fiji (https://imagej.net/Fiji) using the polygon tool. __The ROI zip file must end in \"_RoiSet\" with the extension \".zip\"__. If ROIs have not been drawn, it is recommended to use option 2 below (using files_to_analyze.py) and perform the preprocessing in two runs/executions of this code (main_parallel). For the __first run__, perform only the motion correction step. Take the H5 motion-corrected output and load it into FIJI (https://imagej.net/Fiji), manually draw ROIs, and save the ROIs. Then (__second run__) edit files_to_analyze.py now setting signal_extraction and neuropil_correction to True, and rerun this notebook/script (main_parallel).\n",
    "\n",
    "How to run this code\n",
    "------------------------------------\n",
    "\n",
    "__In this jupyter notebook, just run all cells in order (shift + enter). When you reach the last cell, it will prompt the user for input. You have two options:__\n",
    "\n",
    "1) __Input the path to the root directory__ that contains the raw files. For example, if your files are in a folder called analyze_sessions: C:\\Users\\my_user\\analyze_sessions  \n",
    "This will by default attempt to run motion correction, signal extraction, and neuropil extraction. You will encounter an error if ROI masks are not saved to the same directory as the raw data.\n",
    "\n",
    "2) You can also indicate specific files, parameters, and processing steps to include by __editing the python script called files_to_analyze.py__ (in the same directory as this main_parallel.ipynb). Once you have specified the files in files_to_analyze.py and saved, run this notebooks' cells, leave the input blank, and press enter; this code will automatically load the information in files_to_analyze.py.\n",
    "\n",
    "To execute this in command line and follow the same directions as above:  \n",
    "`python main_parallel.py`\n",
    "\n",
    "\n",
    "See these documentations for details about SIMA\n",
    "------------------------------------\n",
    "\n",
    "https://github.com/losonczylab/sima  \n",
    "http://www.losonczylab.org/sima/1.3.2/  \n",
    "https://www.frontiersin.org/articles/10.3389/fninf.2014.00080/full\n",
    "\n",
    "Required Packages\n",
    "-----------------\n",
    "Python 2.7, sima, glob, multiprocessing, numpy, h5py, pickle (optional if want to save displacement file) \n",
    "\n",
    "Custom code requirements: sima_motion_correction, bidi_offset_correction, calculate_neuropil (written by Vijay Namboodiri), files_to_analyze\n",
    "\n",
    "Parameters (Only relevant if using the subfunction batch_process; ignore if using files_to_analyze or using default params by inputting a file directory)\n",
    "----------\n",
    "\n",
    "fdir : string\n",
    "    root file directory containing the raw tif, tiff, h5 files. Note: leave off the last backslash. For example: C:\\Users\\my_user\\analyze_sessions\n",
    "    \n",
    "motion_correct : bool\n",
    "    \n",
    "    If true, runs sima motion correction on tif or h5 specified.\n",
    "    If motion_correct flag set to false and there's no .sima folder, bypass sima MC but still make a .sima folder with sequences to allow for downstream processing \n",
    "\n",
    "Optional Parameters (Only relevant if using batch_process)\n",
    "-------------------\n",
    "\n",
    "max_disp : list of two entries\n",
    "    Each entry is an int. First entry is the y-axis maximum allowed displacement, second is the x-axis max allowed displacement.\n",
    "    The number of pixel shift for each line cannot go above these values.\n",
    "    Note: 50 pixels is approximately 10% of the FOV (512x512 pixels)\n",
    "    \n",
    "    Defaults to [30, 50]\n",
    "    \n",
    "save_displacement : bool \n",
    "    Whether or not to have SIMA save the calculated displacements over time. def: False; NOTE: if this is switched to True,\n",
    "    it can double the time to perform motion correction.\n",
    "    \n",
    "    Defaults to False\n",
    "    \n",
    "Output\n",
    "-------\n",
    "motion corrected file (in the format of h5) with \"\\_sima_mc\" appended to the end of the file name\n",
    "\n",
    "\"\\*\\_sima_masks.npy\" : numpy data file  \n",
    "  * 3D array containing 2D masks for each ROI\n",
    "\n",
    "\"\\*_extractedsignals.npy\" : numpy data file  \n",
    "  * array containing pixel-averaged activity time-series for each ROI\n",
    "   \n",
    "\"\\_spatial_weights_*.h5\" : h5 file  \n",
    "  * contains spatial weighting masks of neuropil for each ROI\n",
    "\n",
    "\"\\_neuropil_signals_*.npy\" : numpy data file  \n",
    "  * array containing neuropil signals for each ROI\n",
    "\n",
    "\"\\_neuropil_corrected_signals_*.npy\" : numpy data file  \n",
    "  * array containing neuropil-corrected signals for each ROI\n",
    "\n",
    "\"\\*.json\" : json file\n",
    "  * file containing the analysis parameters (fparams). Set by files_to_analyze.py or default parameters.\n",
    "  * to view the data, one can easily open in a text editor (eg. word or wordpad).\n",
    "\n",
    "output_images : folder containing images  \n",
    "    You will also find a folder containing plots that reflect how each executed preprocessing step performed. Examples are mean images for motion corrected data, ROI masks overlaid on mean images, extracted signals for each ROI, etc..\n",
    "\n",
    "note: * is a wildcard indicating additional characters present in the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import native python packages\n",
    "import glob\n",
    "from fnmatch import fnmatch\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# import custom codes\n",
    "import sima_motion_bidi_correction \n",
    "import calculate_neuropil\n",
    "import single_file_process\n",
    "import files_to_analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(root_dir, max_disp = [30, 50], save_displacement = False):\n",
    "    \n",
    "    if not root_dir: # if string is empty, load predefined list of files in files_to_analyze\n",
    "        \n",
    "        fparams = files_to_analyze.define_fparams()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        root_dir = root_dir + '\\\\'\n",
    "\n",
    "        # declare initialize variables to do with finding files to analyze\n",
    "        fparams = []\n",
    "        fpaths = []\n",
    "        types = ['*.tif', '*.tiff', '*.h5']\n",
    "        exclude_strs = ['spatialweights', '_sima_mc', '_trim_dims', '_offset_vals']\n",
    "\n",
    "        # find files to analyze\n",
    "        for path, subdirs, files in os.walk(root_dir): # os.walk grabs all paths and files in subdirectories\n",
    "            for name in files:\n",
    "                # make sure file of any image file\n",
    "                if any([fnmatch(name, ext) for ext in types]) and not any([exclude_str in name for exclude_str in exclude_strs]): # but don't include processed files\n",
    "                    tmp_dict = {}\n",
    "                    tmp_dict['fname'] = name\n",
    "                    tmp_dict['fdir'] = path\n",
    "                    tmp_dict['max_disp'] = max_disp\n",
    "                    tmp_dict['save_displacement'] = save_displacement\n",
    "\n",
    "                    print(tmp_dict['fname'])\n",
    "                    fparams.append(tmp_dict)\n",
    "                    \n",
    "    # print info to console\n",
    "    num_files = len(fparams)\n",
    "    if num_files == 0:\n",
    "        raise Exception(\"No files to analyze!\")\n",
    "    print(str(num_files) + ' files to analyze')\n",
    "    \n",
    "    # determine number of cores to use and initialize parallel pool\n",
    "    num_processes = min(mp.cpu_count(), num_files)\n",
    "    print('Total CPU cores for parallel processing: ' + str(num_processes))\n",
    "    pool = mp.Pool(processes=num_processes)\n",
    "    \n",
    "    # perform parallel processing; pass iterable list of file params to the analysis module selection code\n",
    "    pool.map(single_file_process.process, fparams)\n",
    "    \n",
    "    ## for testing\n",
    "    #for fparam in fparams:\n",
    "    #    single_file_process.process(fparam) \n",
    "\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    fdir = input(r\"Input root directory of tif, tiff, h5 files to analyze; note: Use FORWARD SLASHES to separate folder and leave the last backlash off!!  Otherwise leave blank to use files declared in file_to_analyze.py\")\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    \n",
    "    batch_process(fdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
